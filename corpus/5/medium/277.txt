
# Turbo code

### From Wikipedia, the free encyclopedia

Jump to: navigation, search

In electrical engineering and digital communications, turbo codes (originally
in French Turbocodes) are a class of high-performance error correction codes
developed in 1993 which are finding use in deep space satellite communications
and other applications where designers seek to achieve maximal information
transfer over a limited-bandwidth communication link in the presence of data-
corrupting noise.

## Contents

  * 1 Advantages
  * 2 Disadvantages
  * 3 History
  * 4 The encoder
  * 5 The decoder
  * 6 Soft decision approach
  * 7 Solving hypotheses to find bits
  * 8 Practical applications using Turbo Codes
  * 9 Bayesian formulation
  * 10 See also
  * 11 References
  * 12 External links

  
## [edit] Advantages

Of all practical error correction methods known to date, turbo codes and low-
density parity-check codes (LDPCs) come closest to approaching the Shannon
limit, the theoretical limit of maximum information transfer rate over a noisy
channel.

Turbo codes make it possible to increase data rate without increasing the
power of a transmission, or they can be used to decrease the amount of power
used to transmit at a certain data rate. Their main drawbacks are the
relatively high decoding complexity and relatively high latency, which make
them unsuitable for some applications. For satellite use, this is not of great
concern, since the transmission distance itself introduces latency due to the
finite propagation speed.

Prior to Turbo codes, because practical implementations of LDPCs had not been
developed, the most widespread technique that approached the Shannon limit
combined Reed-Solomon error correction block codes with Viterbi-decoded short
constraint length convolutional codes, also known as RSV codes.

  

<IMG>

<IMG>

NASA's Deep Space Missions ECC Codes (code imperfectness)

  

## [edit] Disadvantages

The complexity of these algorithms and the fact that these algorithms have
encumbering software patents were considered to be disadvantages of
implementing these algorithms in a system. Today, many modern systems use
turbo codes.

## [edit] History

The method was introduced by Berrou, Glavieux, and Thitimajshima (from
Telecom-Bretagne former:ENST Bretagne, France) in their 1993 paper: "Near
Shannon Limit Error-correcting Coding and Decoding: Turbo-codes" published in
the Proceedings of IEEE International Communications Conference [1]. In a
later paper, Berrou gave credit to the "intuition"of "G. Battail, J. Hagenauer
and P. Hoeher, who, in the late 80s, highlighted the interest of probabilistic
processing.". He adds "R. Gallager and M. Tanner had already imagined coding
and decoding techniques whose general principles are closely related,"
although the necessary calculations were impractical at that time. [2]

## [edit] The encoder

The encoder sends three sub-blocks of bits. The first sub-block is the m-bit
block of payload data. The second sub-block is n/2 parity bits for the payload
data, computed using a recursive systematic convolutional code (RSC code). The
third sub-block is n/2 parity bits for a known permutation of the payload
data, again computed using an RSC convolutional code. That is, two redundant
but different sub-blocks of parity bits for the sent payload. The complete
block has m+n bits of data with a code rate of m/(m+n). The permutation of the
payload data is carried out by a device called an interleaver.

Hardware-wise, turbo-code encoder consists of two identical RSC coders, Ð¡1
and C2, as depicted on the figure, which are connected to each other using a
concatenation scheme, called parallel concatenation:

Image:turbo encoder.svg

On the figure, M is a memory register. Delay line and interleaver force input
bits dk to appear in different sequences. At first iteration, the input
sequence dk appears at both outputs of the encoder, xk and y1k or y2k due to
the encoder's systematic character. If the encoders C1 and C2 are used
respectively in n1 and n2 iterations, their rates are respectively equal to

~R_1=\\frac{n_1+n_2}{2n_1+n_2}, ~R_2=\\frac{n_1+n_2}{2n_2+n_1}.

## [edit] The decoder

The decoder is built in the similar way as the above encoder - two elementary
decoders are interconnected to each other, but in serial way, not parallel.
The DEC1 decoder operates on lower speed (i.e. R1), thus, it is intended for
the C1 encoder, and DEC2 is for C2 correspondingly. DEC1 yields a soft
decision which causes L1 delay. The same delay is caused by the delay line in
the encoder. The DEC2's operation causes L2 delay.

Image:turbo decoder.svg

An interleaver installed between two decoders is used here to scatter error
bursts coming from DEC1 output. DI block is a demultiplexing and insertion
module. It works as a switch, redirecting input bits to DEC1 at one moment and
to DEC2 at another. In OFF state, it feeds both y1k and y2k inputs with
padding bits (zeros).

Consider a memoryless AWGN channel and assume that at k-th iteration, the
decoder receives a couple of random variables:

~x_k=\(2d_k-1\)+a_k,  
~y_k=2\(Y_k-1\)+b_k

where ak and bk are independent noise components having the same variance Ï2.
Yk is a k-th bit from yk encoder output.

Redundant information is demultiplexed and sent through DI to DEC1 (when yk =
y1k) and to DEC2 (when yk = y2k).

DEC1 yields a soft decision, i.e.:

\\Lambda\(d_k\)=\\log\\frac{p\(d_k=1\)}{p\(d_k=0\)}

and delivers it to DEC2. Î(dk) is called the logarithm of likelihood ratio
(LLR). p\(d_k=i\), i \\in \\{0,1\\} is a posteriori probability (APP) of the
dk data bit which shows the probability of interpreting a received dk bit as
i. Taking LLR into account, DEC2 yields a hard decision, i.e. a decoded bit.

It's well known that a Viterbi algorithm is unable to calculate APP, thus it
cannot be used in DEC1. Instead of that, modified BCJR algorithm is used. For
DEC2, Viterbi algorithm is an appropriate one.

However, the depicted structure is not optimal, because DEC1 uses only a
fraction of available redundant information. In order to improve the
structure, a feedback loop is used (dotted line on the figure).

## [edit] Soft decision approach

The decoder front-end produces an integer for each bit in the data stream.
This integer is a measure of how likely it is that the bit is a 0 or 1 and is
also called soft bit. The integer could be drawn from the range [-127, 127],
where:

  * -127 means "certainly 0"
  * -100 means "very likely 0"
  * 0 means "it could be either 0 or 1"
  * 100 means "very likely 1"
  * 127 means "certainly 1"
  * etc

This introduces a probabilistic aspect to the data-stream from the front end,
but it conveys more information about each bit than just 0 or 1.

For example, for each bit, the front end of a traditional wireless-receiver
has to decide if an internal analog voltage is above or below a given
threshold voltage level. For a turbo-code decoder, the front end would provide
an integer measure of how far the internal voltage is from the given
threshold.

To decode the m+n-bit block of data, the decoder front-end creates a block of
likelihood measures, with one likelihood measure for each bit in the data
stream. There are two parallel decoders, one for each of the n/2-bit parity
sub-blocks. Both decoders use the sub-block of m likelihoods for the payload
data. The decoder working on the second parity sub-block knows the permutation
that the coder used for this sub-block.

## [edit] Solving hypotheses to find bits

The key innovation of turbo codes is how they use the likelihood data to
reconcile differences between the two decoders. Each of the two convolutional
decoders generates a hypothesis (with derived likelihoods) for the pattern of
m bits in the payload sub-block. The hypothesis bit-patterns are compared, and
if they differ, the decoders exchange the derived likelihoods they have for
each bit in the hypotheses. Each decoder incorporates the derived likelihood
estimates from the other decoder to generate a new hypothesis for the bits in
the payload. Then they compare these new hypotheses. This iterative process
continues until the two decoders come up with the same hypothesis for the
m-bit pattern of the payload, typically in 15 to 18 cycles.

An analogy can be drawn between this process and that of solving cross-
reference puzzles like crossword or sudoku. Consider a partially-completed,
possibly garbled crossword puzzle. Two puzzle solvers (decoders) are trying to
solve it: one possessing only the "down" clues (parity bits), and the other
possessing only the "across" clues. To start, both solvers guess the answers
(hypotheses) to their own clues, noting down how confident they are in each
letter (payload bit). Then, they compare notes, by exchanging answers and
confidence ratings with each other, noticing where and how they differ. Based
on this new knowledge, they both come up with updated answers and confidence
ratings, repeating the whole process until they converge to the same solution.

## [edit] Practical applications using Turbo Codes

Telecommunications:

  * Turbo codes are used extensively in 3G mobile telephony standards.
  * MediaFLO, terrestrial mobile television system from Qualcomm
  * New NASA missions such as Mars Reconnaissance Orbiter now use Turbo Codes, as an alternative to RS-Viterbi codes.
  * Turbo coding such as Block Turbo Coding and Convolutional Turbo Coding are used in IEEE 802.16, a wireless metropolitan network standard.

## [edit] Bayesian formulation

From an artificial intelligence viewpoint, turbo codes can be considered as an
instance of loopy belief propagation in Bayesian networks.

## [edit] See also

  * Convolutional code
  * Viterbi algorithm
  * Soft decision
  * Interleaver
  * BCJR algorithm
  * Low-density parity-check code

## [edit] References

  1. ^ Near Shannon Limit error-correcting coding and decoding: Turbo-codes
  2. ^ Ten-year-old Turbo Codes are Entering Service, Claude Berrou, ENST Bretagne

## [edit] External links

  * "The UMTS Turbo Code and an Efficient Decoder Implementation Suitable for Software-Defined Radios" (International Journal of Wireless Information Networks)
  * Dana Mackenzie (2005). "Take it to the limit". New Scientist 187 (2507): 38â41. ISSN 0262-4079. (preview, copy)
  * "Pushing the Limit", a Science News feature about the development and genesis of turbo codes
  * Coded Modulation Library, an open source library for simulating turbo codes in matlab
  * "Turbo Equalization: Principles and New Results", an IEEE Transactions on Communications article about using convolutional codes jointly with channel equalization.
  * "PDF Slideshow illustrating the decoding process" A PDF Slideshow illustrating the decoding process

Retrieved from "http://en.wikipedia.org/wiki/Turbo_code"

Categories: Error detection and correction

##### Views

  * Article
  * Discussion
  * Edit this page
  * History

##### Personal tools

  * Log in / create account

##### Navigation

  * Main page
  * Contents
  * Featured content
  * Current events
  * Random article

##### Search



##### Interaction

  * About Wikipedia
  * Community portal
  * Recent changes
  * Contact Wikipedia
  * Donate to Wikipedia
  * Help

##### Toolbox

  * What links here
  * Related changes
  * Upload file
  * Special pages
  * Printable version
  * Permanent link
  * Cite this page

##### Languages

  * FranÃ§ais
  * Deutsch
  * æ¥æ¬èª
  * Nederlands
  * Italiano
  * Ð ÑÑÑÐºÐ¸Ð¹

Powered by MediaWiki

Wikimedia Foundation

  * This page was last modified on 13 April 2009, at 06:49 (UTC).
  * All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)   
Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S.
registered 501(c)(3) tax-deductible nonprofit charity.  

  * Privacy policy
  * About Wikipedia
  * Disclaimers



