
# Machine translation

### From Wikipedia, the free encyclopedia

Jump to: navigation, search

<IMG>

This article needs additional citations for verification. Please help improve
this article by adding reliable references (ideally, using inline citations).
Unsourced material may be challenged and removed. (June 2008)  
Machine translation, sometimes referred to by the abbreviation MT, is a sub-
field of computational linguistics that investigates the use of computer
software to translate text or speech from one natural language to another. At
its basic level, MT performs simple substitution of words in one natural
language for words in another. Using corpus techniques, more complex
translations may be attempted, allowing for better handling of differences in
linguistic typology, phrase recognition, and translation of idioms, as well as
the isolation of anomalies.

Current machine translation software often allows for customisation by domain
or profession (such as weather reports) â improving output by limiting the
scope of allowable substitutions. This technique is particularly effective in
domains where formal or formulaic language is used. It follows then that
machine translation of government and legal documents more readily produces
usable output than conversation or less standardised text.

Improved output quality can also be achieved by human intervention: for
example, some systems are able to translate more accurately if the user has
unambiguously identified which words in the text are names. With the
assistance of these techniques, MT has proven useful as a tool to assist human
translators, and in some cases can even produce output that can be used "as
is".

## Contents

  * 1 History
  * 2 Translation process
  * 3 Approaches
    * 3.1 Rule-based
    * 3.2 Statistical
    * 3.3 Example-based
  * 4 Major issues
    * 4.1 Disambiguation
    * 4.2 Named entities
  * 5 Applications
  * 6 Evaluation
  * 7 See also
  * 8 Notes
  * 9 References
  * 10 External links
    * 10.1 Software

  
## [edit] History

Main article: History of machine translation

The idea of machine translation may be traced back to 17th century. In 1629,
RenÃ© Descartes proposed a universal language, with equivalent ideas in
different tongues sharing one symbol. In the 1950s, The Georgetown experiment
(1954) involved fully-automatic translation of over sixty Russian sentences
into English. The experiment was a great success and ushered in an era of
substantial funding for machine-translation research. The authors claimed that
within three to five years, machine translation would be a solved problem.

Real progress was much slower, however, and after the ALPAC report (1966),
which found that the ten-year-long research had failed to fulfill
expectations, funding was greatly reduced. Beginning in the late 1980s, as
computational power increased and became less expensive, more interest was
shown in statistical models for machine translation.

The idea of using digital computers for translation of natural languages was
proposed as early as 1946 by A. D. Booth and possibly others. The Georgetown
experiment was by no means the first such application, and a demonstration was
made in 1954 on the APEXC machine at Birkbeck College (University of London)
of a rudimentary translation of English into French. Several papers on the
topic were published at the time, and even articles in popular journals (see
for example Wireless World, Sept. 1955, Cleave and Zacharov). A similar
application, also pioneered at Birkbeck College at the time, was reading and
composing Braille texts by computer.

## [edit] Translation process

Main article: Translation process

The translation process may be stated as:

  1. Decoding the meaning of the source text; and
  2. Re-encoding this meaning in the target language.

Behind this ostensibly simple procedure lies a complex cognitive operation. To
decode the meaning of the source text in its entirety, the translator must
interpret and analyse all the features of the text, a process that requires
in-depth knowledge of the grammar, semantics, syntax, idioms, etc., of the
source language, as well as the culture of its speakers. The translator needs
the same in-depth knowledge to re-encode the meaning in the target language.

Therein lies the challenge in machine translation: how to program a computer
that will "understand" a text as a person does, and that will "create" a new
text in the target language that "sounds" as if it has been written by a
person.

This problem may be approached in a number of ways.

## [edit] Approaches

<IMG>

<IMG>

Pyramid showing comparative depths of intermediary representation,
interlingual machine translation at the peak, followed by transfer-based, then
direct translation.

Machine translation can use a method based on linguistic rules, which means
that words will be translated in a linguistic way â the most suitable
(orally speaking) words of the target language will replace the ones in the
source language.

It is often argued that the success of machine translation requires the
problem of natural language understanding to be solved first.

Generally, rule-based methods parse a text, usually creating an intermediary,
symbolic representation, from which the text in the target language is
generated. According to the nature of the intermediary representation, an
approach is described as interlingual machine translation or transfer-based
machine translation. These methods require extensive lexicons with
morphological, syntactic, and semantic information, and large sets of rules.

Given enough data, machine translation programs often work well enough for a
native speaker of one language to get the approximate meaning of what is
written by the other native speaker. The difficulty is getting enough data of
the right kind to support the particular method. For example, the large
multilingual corpus of data needed for statistical methods to work is not
necessary for the grammar-based methods. But then, the grammar methods need a
skilled linguist to carefully design the grammar that they use.

To translate between closely related languages, a technique referred to as
shallow-transfer machine translation may be used.

### [edit] Rule-based

The rule-based machine translation paradigm includes transfer-based machine
translation, interlingual machine translation and dictionary-based machine
translation paradigms.

Main article: Rule-based machine translation

Transfer-based machine translation

Main article: Transfer-based machine translation

Interlingual

Main article: Interlingual machine translation

Interlingual machine translation is one instance of rule-based machine-
translation approaches. In this approach, the source language, i.e. the text
to be translated, is transformed into an interlingual, i.e. source-/target-
language-independent representation. The target language is then generated out
of the interlingua.

Dictionary-based

Main article: Dictionary-based machine translation

Machine translation can use a method based on dictionary entries, which means
that the words will be translated as they are by a dictionary.

### [edit] Statistical

Main article: Statistical machine translation

Statistical machine translation tries to generate translations using
statistical methods based on bilingual text corpora, such as the Canadian
Hansard corpus, the English-French record of the Canadian parliament and
EUROPARL, the record of the European Parliament. Where such corpora are
available, impressive results can be achieved translating texts of a similar
kind, but such corpora are still very rare. The first statistical machine
translation software was CANDIDE from IBM. Google used SYSTRAN for several
years, but has switched to a statistical translation method in October 2007.
Recently, they improved their translation capabilities by inputting
approximately 200 billion words from United Nations materials to train their
system. Accuracy of the translation has improved. [1]

### [edit] Example-based

Main article: Example-based machine translation

Example-based machine translation (EBMT) approach is often characterised by
its use of a bilingual corpus as its main knowledge base, at run-time. It is
essentially a translation by analogy and can be viewed as an implementation of
case-based reasoning approach of machine learning.

## [edit] Major issues

### [edit] Disambiguation

Main article: Word sense disambiguation

Word-sense disambiguation concerns finding a suitable translation when a word
can have more than one meaning. The problem was first raised in the 1950s by
Yehoshua Bar-Hillel.[2] He pointed out that without a "universal
encyclopedia", a machine would never be able to distinguish between the two
meanings of a word.[3] Today there are numerous approaches designed to
overcome this problem. They can be approximately divided into "shallow"
approaches and "deep" approaches.

Shallow approaches assume no knowledge of the text. They simply apply
statistical methods to the words surrounding the ambiguous word. Deep
approaches presume a comprehensive knowledge of the word. So far, shallow
approaches have been more successful.[citation needed]

The late Claude Piron, a long-time translator for the United Nations and the
World Health Organization, wrote that machine translation, at its best,
automates the easier part of a translator's job; the harder and more time-
consuming part usually involves doing extensive research to resolve
ambiguities in the source text, which the grammatical and lexical exigencies
of the target language require to be resolved:

    Why does a translator need a whole workday to translate five pages, and not an hour or two? ..... About 90% of an average text corresponds to these simple conditions. But unfortunately, there's the other 10%. It's that part that requires six [more] hours of work. There are the ambiguities one has to resolve. For instance, the author of the source text, an Australian physician, cited the example of an epidemic which was declared during World War II in a "Japanese prisoner of war camp". Was he talking about an American camp with Japanese prisoners or a Japanese camp with American prisoners? The English has two senses. It's necessary therefore to do research, maybe to the extent of a phone call to Australia. [4]
The ideal deep approach would require the translation software to do all the
research necessary for this kind of disambiguation on its own; but this would
require a higher degree of AI than has yet been attained. A shallow approach
which simply guessed at the sense of the ambiguous English phrase that Piron
mentions (based, perhaps, on which kind of prisoner-of-war camp is more often
mentioned in a given corpus) would have a reasonable chance of guessing wrong
fairly often. A shallow approach that involves "ask the user about each
ambiguity" would, by Piron's estimate, only automate about 25% of a
professional translator's job, leaving the harder 75% still to be done by a
human.

### [edit] Named entities

Related to named entity recognition in information extraction.

## [edit] Applications

There are now many software programs for translating natural language, several
of them online, such as:

  * SYSTRAN, which powers Yahoo's Babel Fish
  * Promt, which powers online translation services at Voila.fr and Orange.fr

Although no system provides the holy grail of fully automatic high-quality
machine translation, many systems produce reasonable output.

Despite their inherent limitations, MT programs are used around the world.
Probably the largest institutional user is the European Commission.

Toggletext uses a transfer-based system (known as Kataku) to translate between
English and Indonesian.

Google has claimed that promising results were obtained using a proprietary
statistical machine translation engine.[5] The statistical translation engine
used in the Google language tools for Arabic <-> English and Chinese <->
English has an overall score of 0.4281 over the runner-up IBM's BLEU-4 score
of 0.3954 (Summer 2006) in tests conducted by the National Institute for
Standards and Technology.[6][7][8]

With the recent focus on terrorism, the military sources in the United States
have been investing significant amounts of money in natural language
engineering. In-Q-Tel[9] (a venture capital fund, largely funded by the US
Intelligence Community, to stimulate new technologies through private sector
entrepreneurs) brought up companies like Language Weaver. Currently the
military community is interested in translation and processing of languages
like Arabic, Pashto, and Dari.[citation needed] Information Processing
Technology Office in DARPA hosts programs like TIDES and Babylon Translator.
US Air Force has awarded a $1 million contract to develop a language
translation technology.[10]

## [edit] Evaluation

Main article: Evaluation of machine translation

There are various means for evaluating the performance of machine-translation
systems. The oldest is the use of human judges[11] to assess a translation's
quality. Even though human evaluation is time-consuming, it is still the most
reliable way to compare different systems such as rule-based and statistical
systems. Automated means of evaluation include BLEU, NIST and METEOR.

Relying exclusively on unedited machine translation ignores the fact that
communication in human language is context-embedded, and that it takes a human
to adequately comprehend the context of the original text. Even purely human-
generated translations are prone to error. Therefore, to ensure that a
machine-generated translation will be of publishable quality and useful to a
human, it must be reviewed and edited by a human.

It has, however, been asserted that in certain applications, e.g. product
descriptions written in a controlled language, a dictionary-based machine-
translation system has produced satisfactory translations that require no
human intervention.[12]

## [edit] See also

  * Comparison of Machine translation applications
  * Artificial Intelligence
  * Computational linguistics
  * Universal Networking Language
  * Computer-assisted translation and Translation memory
  * Controlled natural language
  * History of machine translation
  * Human Language Technology
  * List of emerging technologies
  * List of research laboratories for machine translation
  * Pseudo-translation
  * Translation
  * Universal translator
  * Wiktionary:Translations
  * Phraselator
  * Mobile translation

## [edit] Notes

  1. ^ Google Translator: The Universal Language
  2. ^ Milestones in machine translation - No.6: Bar-Hillel and the nonfeasibility of FAHQT by John Hutchins
  3. ^ Bar-Hillel (1960), "Automatic Translation of Languages". Available online at http://www.mt-archive.info/Bar-Hillel-1960.pdf
  4. ^ Claude Piron, Le dÃ©fi des langues (The Language Challenge), Paris, L'Harmattan, 1994.
  5. ^ Google Blog: The machines do the translating (by Franz Och)
  6. ^ Geer, David, "Statistical Translation Gains Respect", pp. 18 - 21, IEEE Computer, October 2005
  7. ^ Ratcliff, Evan "Me Translate Pretty One Day", Wired December 2006
  8. ^ "NIST 2006 Machine Translation Evaluation Official Results", November 1, 2006
  9. ^ In-Q-Tel
  10. ^ GCN â Air force wants to build a universal translator
  11. ^ Comparison of MT systems by human evaluation, May 2008
  12. ^ Muegge (2006), "Fully Automatic High Quality Machine Translation of Restricted Text: A Case Study," in Translating and the computer 28. Proceedings of the twenty-eighth international conference on translating and the computer, 16-17 November 2006, London, London: Aslib. ISBN 978-0-85142-483-5.

## [edit] References

  * Hutchins, W. John; and Harold L. Somers (1992). An Introduction to Machine Translation. London: Academic Press. ISBN 0-12-362830-X. http://www.hutchinsweb.me.uk/IntroMT-TOC.htm.
  * Claude Piron, Le dÃ©fi des langues â Du gÃ¢chis au bon sens (The Language Challenge: From Chaos to Common Sense), Paris, L'Harmattan, 1994.

## [edit] External links

Sister project Wikiversity has learning materials about Topic:Computational
linguistics  
  * International Association for Machine Translation (IAMT)
  * Machine Translation, an introductory guide to MT by D.J.Arnold et al. (1994)
  * Machine Translation Archive by John Hutchins. An electronic repository (and bibliography) of articles, books and papers in the field of machine translation and computer-based translation technology
  * Machine translation (computer-based translation) â Publications by John Hutchins (includes PDFs of several books on machine translation)
  * Machine Translation and Minority Languages
  * John Hutchins 1999

### [edit] Software

  * Apertium - an open-source shallow-transfer machine translation engine and toolbox
  * A Punjabi To Hindi Machine Translation System
  * Moses - an open source toolkit for phrase-based statistical machine translation

Approaches to Machine translation  
Dictionary-based Â· Rule-based (RBMT) Â· Transfer-based Â· Statistical (SMT)
Â· Example-based (EBMT) Â· Interlingual  
  

Retrieved from "http://en.wikipedia.org/wiki/Machine_translation"

Categories: Artificial intelligence applications | Computational linguistics |
Machine translation | Computer-assisted translation | Natural language
processing

Hidden categories: Articles needing additional references from June 2008 | All
articles with unsourced statements | Articles with unsourced statements since
April 2007 | Articles with unsourced statements since February 2007

##### Views

  * Article
  * Discussion
  * Edit this page
  * History

##### Personal tools

  * Log in / create account

##### Navigation

  * Main page
  * Contents
  * Featured content
  * Current events
  * Random article

##### Search



##### Interaction

  * About Wikipedia
  * Community portal
  * Recent changes
  * Contact Wikipedia
  * Donate to Wikipedia
  * Help

##### Toolbox

  * What links here
  * Related changes
  * Upload file
  * Special pages
  * Printable version
  * Permanent link
  * Cite this page

##### Languages

  * Afrikaans
  * Ø§ÙØ¹Ø±Ø¨ÙØ©
  * ÐÐµÐ»Ð°ÑÑÑÐºÐ°Ñ
  * ÐÐµÐ»Ð°ÑÑÑÐºÐ°Ñ (ÑÐ°ÑÐ°ÑÐºÐµÐ²ÑÑÐ°)
  * ÐÑÐ»Ð³Ð°ÑÑÐºÐ¸
  * CatalÃ 
  * Äesky
  * Cymraeg
  * Dansk
  * Deutsch
  * EspaÃ±ol
  * Esperanto
  * Euskara
  * ÙØ§Ø±Ø³Û
  * FranÃ§ais
  * íêµ­ì´
  * à¤¹à¤¿à¤¨à¥à¤¦à¥
  * Hrvatski
  * Bahasa Indonesia
  * Italiano
  * ×¢××¨××ª
  * LietuviÅ³
  * Magyar
  * Bahasa Melayu
  * Nederlands
  * æ¥æ¬èª
  * âªNorsk (bokmÃ¥l)â¬
  * Occitan
  * Polski
  * PortuguÃªs
  * RomÃ¢nÄ
  * Ð ÑÑÑÐºÐ¸Ð¹
  * Simple English
  * SlovenÄina
  * Ð¡ÑÐ¿ÑÐºÐ¸ / Srpski
  * Suomi
  * Svenska
  * à®¤à®®à®¿à®´à¯
  * à¹à¸à¸¢
  * Tiáº¿ng Viá»t
  * Ð¢Ð¾Ò·Ð¸ÐºÓ£
  * Ð£ÐºÑÐ°ÑÐ½ÑÑÐºÐ°
  * å´è¯­
  * ç²µèª
  * ä¸­æ

Powered by MediaWiki

Wikimedia Foundation

  * This page was last modified on 2 April 2009, at 03:24.
  * All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)   
Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S.
registered 501(c)(3) tax-deductible nonprofit charity.  

  * Privacy policy
  * About Wikipedia
  * Disclaimers



