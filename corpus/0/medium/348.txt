
# Generalized linear model

### From Wikipedia, the free encyclopedia

Jump to: navigation, search

Not to be confused with general linear model.

In statistics, the generalized linear model (GLM) is a flexible generalization
of ordinary least squares regression. The GLM generalizes linear regression by
allowing the linear model to be related to the response variable via a link
function and by allowing the magnitude of the variance of each measurement to
be a function of its predicted value.

Generalized linear models were formulated by John Nelder and Robert Wedderburn
as a way of unifying various other statistical models, including linear
regression, logistic regression and Poisson regression, under one
framework.[1] This allowed them to develop a general algorithm for maximum
likelihood estimation in all these models. It extends naturally to encompass
many other models as well.

## Contents

  * 1 Overview
  * 2 Model components
    * 2.1 Distribution function
    * 2.2 Linear predictor
    * 2.3 Link function
  * 3 Examples
    * 3.1 General linear models
    * 3.2 Linear regression
    * 3.3 Binomial data
    * 3.4 Count data
  * 4 Extensions
    * 4.1 Correlated or clustered data
    * 4.2 Generalized additive models
    * 4.3 Multinomial regression
      * 4.3.1 Ordered response
      * 4.3.2 Unordered response
  * 5 Etymology
  * 6 External sources
  * 7 References
  * 8 See also
  * 9 External links

  
## [edit] Overview

In a GLM, each outcome of the dependent variables, Y, is assumed to be
generated from a particular distribution function in the exponential family, a
large range of probability distributions that includes the normal, binomial
and poisson distributions, among others. The mean, Î¼, of the distribution
depends on the independent variables, X, through:

    \\operatorname{E}\(\\mathbf{Y}\) = \\boldsymbol{\\mu} = g^{-1}\(\\mathbf{X}\\boldsymbol{\\beta}\) 
where E(Y) is the expected value of Y; XÎ² is the linear predictor, a linear
combination of unknown parameters, Î²; g is the link function.

In this framework, the variance is typically a function, V, of the mean:

     \\operatorname{Var}\(\\mathbf{Y}\) = \\operatorname{V}\( \\boldsymbol{\\mu} \) = \\operatorname{V}\(g^{-1}\(\\mathbf{X}\\boldsymbol{\\beta}\)\). 
It is convenient if V follows from the exponential family distribution, but it
may simply be that the variance is a function of the predicted value.

The unknown parameters, Î², are typically estimated with maximum likelihood,
maximum quasi-likelihood, or Bayesian techniques.

## [edit] Model components

The GLM consists of three elements.

    1\. A distribution function f, from the exponential family.
    2\. A linear predictor Î· = XÎ² .
    3\. A link function g such that E(Y) = Î¼ = g-1(Î·).
### [edit] Distribution function

The exponential family of distributions are those probability distributions,
parameterized by Î¸ and Ï, whose density functions f (or probability mass
function, for the case of a discrete distribution) can be expressed in the
form

     f_Y\(y; \\theta, \\tau\) = \\exp{\\left\(\\frac{a\(y\)b\(\\theta\) - c\(\\theta\)}
                                                {h\(\\tau\)} + 
                                           d\(y,\\tau\) \\right\)}. \\,\\!
Ï, called the dispersion parameter, typically is known and is usually related
to the variance of the distribution. The functions a, b, c, d, and h are
known. Many, although not all, common distributions are in this family.

Î¸ is related to the mean of the distribution. If a is the identity function,
then the distribution is said to be in canonical form. If, in addition, b is
the identity and Ï is known, then Î¸ is called the canonical parameter and is
related to the mean through

     \\mu = \\operatorname{E}\(Y\) = c'\(\\theta\). \\,\\!
Under this scenario, the variance of the distribution can be shown to be[2]

    \\operatorname{Var}\(Y\) = c''\(\\theta\) h\(\\tau\). \\,\\!
### [edit] Linear predictor

The linear predictor is the quantity which incorporates the information about
the independent variables into the model. The symbol Î· (Greek "eta") is
typically used to denote a linear predictor. It is related to the expected
value of the data (thus, "predictor") through the link function.

Î· is expressed as linear combinations (thus, "linear") of unknown parameters
Î². The coefficients of the linear combination are represented as the matrix
of independent variables X. Î· can thus be expressed as

     \\eta = \\mathbf{X}\\boldsymbol{\\beta}.\\,
The elements of X are either measured by the experimenters or stipulated by
them in the modeling design process.

### [edit] Link function

The link function provides the relationship between the linear predictor and
the mean of the distribution function. There are many commonly used link
functions, and their choice can be somewhat arbitrary. It can be convenient to
match the domain of the link function to the range of the distribution
function's mean.

When using a distribution function with a canonical parameter Î¸, a link
function exists which allows for XTY to be a sufficient statistic for Î². This
occurs when the link function equates Î¸ and the linear predictor. Following
is a table of canonical link functions and their inverses (sometimes referred
to as the mean function, as done here) used for several distributions in the
exponential family.

Canonical Link Functions Distribution Name Link Function Mean Function  
Normal Identity \\mathbf{X}\\boldsymbol{\\beta}=\\mu\\,\\!
\\mu=\\mathbf{X}\\boldsymbol{\\beta}\\,\\!  
Exponential Inverse \\mathbf{X}\\boldsymbol{\\beta}=\\mu^{-1}\\,\\!
\\mu=\(\\mathbf{X}\\boldsymbol{\\beta}\)^{-1}\\,\\!  
Gamma  
Inverse  
Gaussian Inverse  
squared \\mathbf{X}\\boldsymbol{\\beta}=\\mu^{-2}\\,\\!
\\mu=\(\\mathbf{X}\\boldsymbol{\\beta}\)^{-1/2}\\,\\!  
Poisson Log \\mathbf{X}\\boldsymbol{\\beta}=\\ln{\(\\mu\)}\\,\\!
\\mu=\\exp{\(\\mathbf{X}\\boldsymbol{\\beta}\)}\\,\\!  
Binomial Logit
\\mathbf{X}\\boldsymbol{\\beta}=\\ln{\\left\(\\frac{\\mu}{1-\\mu}\\right\)}\\,\\!
\\mu=\\frac{\\exp{\(\\mathbf{X}\\boldsymbol{\\beta}\)}}{1 +
\\exp{\(\\mathbf{X}\\boldsymbol{\\beta}\)}} = \\frac{1}{1 +
\\exp{\(-\\mathbf{X}\\boldsymbol{\\beta}\)}}\\,\\!  
Multinomial  
In the cases of the exponential and gamma distributions, the domain of the
canonical link function is not the same as the permitted range of the mean. In
particular, the linear predictor may be negative, which would give an
impossible negative mean. When maximizing the likelihood, precautions must be
taken to avoid this. An alternative is to use a noncanonical link function.

## [edit] Examples

### [edit] General linear models

A possible point of confusion has to do with the distinction between
generalized linear models and the general linear model, two broad statistical
models. The general linear model may be viewed as a case of the generalized
linear model with identity link. As most exact results of interest are
obtained only for the general linear model, the general linear model has
undergone a somewhat longer historical development. Results for the
generalized linear model with non-identity link are asymptotic (tending to
work well with large samples).

### [edit] Linear regression

A simple, very important example of a generalized linear model (also an
example of a general linear model) is linear regression. Here the distribution
function is the normal distribution with constant variance and the link
function is the identity, which is the canonical link if the variance is
known. Unlike most other GLMs, there is a closed form solution for the maximum
likelihood parameter estimates.

### [edit] Binomial data

When the response data, Y, are binary (taking on only values 0 and 1), the
distribution function is generally chosen to be the binomial distribution and
the interpretation of Î¼i is then the probability, p, of Yi taking on the
value one.

There are several popular link functions for binomial functions; the most
typical is the canonical logit link:

    g\(p\) = \\ln \\left\( { p \\over 1-p } \\right\).
GLMs with this setup are logistic regression models.

In addition, the inverse of any continuous cumulative distribution function
(CDF) can be used for the link since the CDF's range is [0, 1], the range of
the binomial mean. The normal CDF Î¦ is a popular choice and yields the probit
model. Its link is

    g\(p\) = \\Phi^{-1}\(p\).\\,\\!
The identity link is also sometimes used for binomial data, but a drawback of
doing this is that the predicted probabilities can be greater than one or less
than zero. In implementation it is possible to fix the nonsensical
probabilities outside of [0,1] but interpreting the coefficients can be
difficult in this model. The model's primary merit is that near p = 0.5 it is
approximately a linear transformation of the probit and
logitâeconometricians sometimes call this the Harvard model.

The variance function for binomial data is given by:

    \\operatorname{Var}\(Y_{i}\)= \\tau\\mu_{i} \(1-\\mu_{i}\)\\,\\!
where the dispersion parameter Ï is typically fixed at exactly one. When it
is not, the resulting quasi-likelihood model often described as binomial with
overdispersion or quasibinomial.

### [edit] Count data

Another example of generalized linear models includes Poisson regression which
models count data using the Poisson distribution. The link is typically the
logarithm, the canonical link.

The variance function is proportional to the mean

    \\operatorname{var}\(Y_{i}\) = \\tau\\mu_{i},\\, 
where the dispersion parameter Ï is typically fixed at exactly one. When it
is not, the resulting quasi-likelihood model is often described as poisson
with overdispersion or quasipoisson.

## [edit] Extensions

### [edit] Correlated or clustered data

The standard GLM assumes that the observations are uncorrelated. Extensions
have been developed to allow for correlation between observations, as occurs
for example in longitudinal studies and clustered designs:

  * Generalized estimating equations (GEEs) allow for the correlation between observations without the use of an explicit probability model for the origin of the correlations, so there is no explicit likelihood. They are suitable when the random effects and their variances are not of inherent interest, as they allow for the correlation without explaining its origin. The focus is on estimating the average response over the population ("population-averaged" effects) rather than the regression parameters that would enable prediction of the effect of changing one or more components of X on a given individual. GEEs are usually used in conjunction with Huber-White standard errors.
  * Generalized linear mixed models (GLMMs) are an extension to GLMs that includes random effects in the linear predictor, giving an explicit probability model that explains the origin of the correlations. The resulting "subject-specific" parameter estimates are suitable when the focus is on estimating the effect of changing one or more components of X on a given individual. GLMMs are a particular type of multilevel model (mixed model). In general, fitting GLMMs is more computationally complex and intensive than fitting GEEs.
  * Hierarchical generalized linear models (HGLMs) are similar to GLMMs apart from two distinctions:

    
  1. The random effects can have any distribution in the exponential family, whereas current GLMMs nearly always have normal random effects;
  2. They are not as computationally intensive, as instead of integrating out the random effects they are based on a modified form of likelihood known as the hierarchical likelihood or h-likelihood.

    The theoretical basis and accuracy of the methods used in HGLMs have been the subject of some debate in the statistical literature. As of 2008, the method is only available in one statistical software package, namely Genstat.[3]
### [edit] Generalized additive models

Generalized additive models (GAMs) [4] are another extension to GLMs in which
the linear predictor Î· is not restricted to be linear in the covariates X but
is an additive function of the xis:

     \\eta = \\beta_0 + f_1\(x_1\) + f_2\(x_2\) + \\ldots \\,\\!
The smooth functions fi are estimated from the data. In general this requires
a large number of data points and is computationally intensive.

### [edit] Multinomial regression

The binomial case may be easily extended to allow for a multinomial
distribution as the response. There are two ways in which this is usually
done:

#### [edit] Ordered response

If the response variable is an ordinal measurement, then one may fit a model
function of the form:

     g\(\\mu_m\) = \\eta_m = \\beta_0 + X_1 \\beta_1 + \\ldots + X_p \\beta_p + \\gamma_2 + \\ldots + \\gamma_m = \\eta_1 + \\gamma_2 + \\ldots + \\gamma_m \\, where  \\mu_m = \\mathrm{P}\(Y \\leq m\) \\,.
for m > 2\. Different links g lead to proportional odds models or ordered
probit models.

#### [edit] Unordered response

If the response variable nominal measurement, or the data does not satisfy the
assumptions of an ordered model, one may fit a model of the following form:

     g\(\\mu_m\) = \\eta_m = \\beta_{m,0} + X_1 \\beta_{m,1} + \\ldots + X_{m,p} \\beta_p \\, where  \\mu_m = \\mathrm{P}\(Y = m \\mid Y \\in \\{1,m\\} \) \\,.
for m > 2\. Different links g lead to multinomial logit or multinomial probit
models. These are less efficient then the ordered response models, as more
parameters are estimated.

## [edit] Etymology

The term "generalized linear model", and especially its abbreviation GLM, can
be confused with general linear model. John Nelder has expressed regret about
this in a conversation with Stephen Senn:

> Senn: I must confess to having some confusion when I was a young
statistician between general linear models and generalized linear models. Do
you regret the terminology?

> Nelder: I think probably I do. I suspect we should have found some more
fancy name for it that would have stuck and not been confused with the general
linear model, although general and generalized are not quite the same. I can
see why it might have been better to have thought of something else.[5]

## [edit] External sources

  * Dobson, A.J.; Barnett, A.G. (2008). Introduction to Generalized Linear Models, Third Edition. London: Chapman and Hall/CRC. [1]

  * Hardin, James; Hilbe, Joseph (2001, 2007). Generalized Linear Models and Extensions. College Station: Stata Press. [2]

  * Hardin, James; Hilbe, Joseph (2003). Generalized Estimating Equations. London: Chapman and Hall/CRC. [3]

  * Hastie, T.J.; Tibshirani, R.J. (1990). Generalized Additive Models. Chapman & Hall/CRC. ISBN 9780412343902. [4]

  * Wood, Simon (2006). Generalized Additive Models: An Introduction with R. Chapman & Hall/CRC. ISBN 1-584-88474-6. [5]

  * McCullagh, Peter; Nelder, John (1989). Generalized Linear Models. London: Chapman and Hall. ISBN 0-412-31760-5. [6]

  * Lee, Youngjo; Nelder, John Pawitan, Yudi (2006). Generalized Linear Models with Random Effects: Unified Analysis via H-likelihood. Boca Raton: Chapman and Hall/CRC. ISBN 1-584-88631-5. [7]

  * Nelder, John; Robert Wedderburn (1972). "Generalized Linear Models". Journal of the Royal Statistical Society. Series A (General) 135: 370â384. doi:10.2307/2344614.

  * Zeger, Scott L.; Liang, Kung-Yee; Albert, Paul S. (1988). "Models for Longitudinal Data: A Generalized Estimating Equation Approach". Biometrics 44 (4): 1049â1060. doi:10.2307/2531734. http://links.jstor.org/sici?sici=0006-341X%28198812%2944%3A4%3C1049%3AMFLDAG%3E2.0.CO%3B2-R.

## [edit] References

  1. ^ McCullagh, Peter; Nelder, John (1989). Generalized Linear Models. London: Chapman and Hall. ISBN 0-412-31760-5. Chapter 1.
  2. ^ McCullagh, Peter; Nelder, John (1989). Generalized Linear Models. London: Chapman and Hall. ISBN 0-412-31760-5. Chapter 2.
  3. ^ Youngjo Lee; John Nelder and Yudi Pawitan (2006). Generalized Linear Models with Random Effects: Unified Analysis via H-likelihood. Chapman & Hall/CRC. http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C6315.
  4. ^ Hastie, T. J. and Tibshirani, R. J. (1990). Generalized Additive Models. Chapman & Hall/CRC. ISBN 9780412343902.
  5. ^ Senn, Stephen (2003). "A conversation with John Nelder". Statistical Science 18 (1): 118â131. doi:10.1214/ss/1056397489. http://projecteuclid.org/euclid.ss/1056397489.

## [edit] See also

  * Tweedie distributions

## [edit] External links

  * Systems Analysis, Modelling and Prediction (SAMP), University of Oxford Open-source MATLAB code for GLM fitting.
  * John Nelder FRS
  * Royal Society citation for Nelder

Retrieved from "http://en.wikipedia.org/wiki/Generalized_linear_model"

Categories: Actuarial science | Regression analysis

##### Views

  * Article
  * Discussion
  * Edit this page
  * History

##### Personal tools

  * Log in / create account

##### Navigation

  * Main page
  * Contents
  * Featured content
  * Current events
  * Random article

##### Search



##### Interaction

  * About Wikipedia
  * Community portal
  * Recent changes
  * Contact Wikipedia
  * Donate to Wikipedia
  * Help

##### Toolbox

  * What links here
  * Related changes
  * Upload file
  * Special pages
  * Printable version
  * Permanent link
  * Cite this page

##### Languages

  * Deutsch
  * Suomi
  * Italiano
  * ä¸­æ

Powered by MediaWiki

Wikimedia Foundation

  * This page was last modified on 31 March 2009, at 00:46 (UTC).
  * All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)   
Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S.
registered 501(c)(3) tax-deductible nonprofit charity.  

  * Privacy policy
  * About Wikipedia
  * Disclaimers



