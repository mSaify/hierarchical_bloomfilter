
# Linear algebra

### From Wikipedia, the free encyclopedia

Jump to: navigation, search

Linear algebra is the branch of mathematics concerned with the study of
vectors, vector spaces (also called linear spaces), linear maps (also called
linear transformations), and systems of linear equations. Vector spaces are a
central theme in modern mathematics; thus, linear algebra is widely used in
both abstract algebra and functional analysis. Linear algebra also has a
concrete representation in analytic geometry and it is generalized in operator
theory. It has extensive applications in the natural sciences and the social
sciences, since nonlinear models can often be approximated by linear ones.

One of the applications of linear algebra is the solution of simultaneous
linear equations. The simplest case is when the number of unknowns is equal to
the number of equations. Therefore, one could begin with the problem of
solving n simultaneous linear equations in n unknowns.[1]

## Contents

  * 1 History
  * 2 Elementary introduction
  * 3 Some useful theorems
  * 4 Generalizations and related topics
  * 5 See also
  * 6 Note
  * 7 References
    * 7.1 Textbooks
    * 7.2 Free Online books
    * 7.3 History
  * 8 External links

  
## [edit] History

The history of modern linear algebra dates back to the early 1840s. In 1843,
William Rowan Hamilton introduced quaternions, which describe mechanics in
three-dimensional space. In 1844, Hermann Grassmann published his book Die
lineale Ausdehnungslehre (see References). Arthur Cayley introduced matrices,
one of the most fundamental linear algebraic ideas, in 1857. Despite these
early developments, linear algebra has been developed primarily in the
twentieth century. It was the focus of one of the first international
mathematical societies, the Quaternion Society, which aimed to study allied
systems of mathematics.

Matrices were poorly-defined before the development of ring theory within
abstract algebra. With the coming of special relativity, many practitioners
gained appreciation of the subtleties of linear algebra. For instance, in 1914
Ludwik Silberstein included an introduction to matrices in his Theory of
Relativity (pp.60-2). Meanwhile, in pure mathematics the routine application
of Cramer's rule to solve partial differential equations led to the inclusion
of linear algebra in standard coursework at universities. Edward Thomas Copson
wrote, for instance,

> When I went to Edinburgh as a young lecturer in 1922, I was surprised to
find how different the curriculum was from that at Oxford. It included topics
such as Lebesgue integration, matrix theory, numerical analysis, Riemannian
geometry, of which I knew nothing...[2]

Francis Galton initiated the use of correlation coefficients in 1888. Often
more than one random variable is in play and may be cross-correlated. In
statistical analysis of multivariate random variables the correlation matrix
is a natural tool. Thus, statistical study of such random vectors helped
establish matrix usage.

More recent developments followed the formulation of the vector space concept
into an algebraic structure, and the growth of functional analysis. One can
see a diverse set of applications in the list of matrices.

## [edit] Elementary introduction

Linear algebra had its beginnings in the study of vectors in Cartesian 2-space
and 3-space. A vector, here, is a directed line segment, characterized by both
its magnitude, represented by length, and its direction. Vectors can be used
to represent physical entities such as forces, and they can be added to each
other and multiplied with scalars, thus forming the first example of a real
vector space.

Modern linear algebra has been extended to consider spaces of arbitrary or
infinite dimension. A vector space of dimension n is called an n-space. Most
of the useful results from 2- and 3-space can be extended to these higher
dimensional spaces. Although people cannot easily visualize vectors in
n-space, such vectors or n-tuples are useful in representing data. Since
vectors, as n-tuples, are ordered lists of n components, it is possible to
summarize and manipulate data efficiently in this framework. For example, in
economics, one can create and use, say, 8-dimensional vectors or 8-tuples to
represent the gross national product of 8 countries. One can decide to display
the GNP of 8 countries for a particular year, where the countries' order is
specified, for example, (United States, United Kingdom, Armenia, Germany,
Brazil, India, Japan, Bangladesh), by using a vector (v1, v2, v3, v4, v5, v6,
v7, v8) where each country's GNP is in its respective position.

A vector space (or linear space), as a purely abstract concept about which
theorems are proved, is part of abstract algebra, and is well integrated into
this discipline. Some striking examples of this are the group of invertible
linear maps or matrices, and the ring of linear maps of a vector space. Linear
algebra also plays an important part in analysis, notably, in the description
of higher order derivatives in vector analysis and the study of tensor
products and alternating maps.

In this abstract setting, the scalars with which an element of a vector space
can be multiplied need not be numbers. The only requirement is that the
scalars form a mathematical structure, called a field. In applications, this
field is usually the field of real numbers or the field of complex numbers.
Linear maps take elements from a linear space to another (or to itself), in a
manner that is compatible with the addition and scalar multiplication given on
the vector space(s). The set of all such transformations is itself a vector
space. If a basis for a vector space is fixed, every linear transform can be
represented by a table of numbers called a matrix. The detailed study of the
properties of and algorithms acting on matrices, including determinants and
eigenvectors, is considered to be part of linear algebra.

One can say quite simply that the linear problems of mathematics \- those that
exhibit linearity in their behavior - are those most likely to be solved. For
example differential calculus does a great deal with linear approximation to
functions. The difference from nonlinear problems is very important in
practice.

The general method of finding a linear way to look at a problem, expressing
this in terms of linear algebra, and solving it, if need be by matrix
calculations, is one of the most generally applicable in mathematics.

## [edit] Some useful theorems

  * Every vector space has a basis.[3]
  * Any two bases of the same vector space have the same cardinality; equivalently, the dimension of a vector space is well-defined.
  * A matrix is invertible if and only if its determinant is nonzero.
  * A matrix is invertible if and only if the linear map represented by the matrix is an isomorphism.
  * If a square matrix has a left inverse or a right inverse then it is invertible (see invertible matrix for other equivalent statements).
  * A matrix is positive semidefinite if and only if each of its eigenvalues is greater than or equal to zero.
  * A matrix is positive definite if and only if each of its eigenvalues is greater than zero.
  * The spectral theorem (regarding diagonalizable matrices).

## [edit] Generalizations and related topics

Since linear algebra is a successful theory, its methods have been developed
in other parts of mathematics. In module theory one replaces the field of
scalars by a ring. In multilinear algebra one considers multivariable linear
transformations, that is, mappings which are linear in each of a number of
different variables. This line of inquiry naturally leads to the idea of the
tensor product. In the spectral theory of operators control of infinite-
dimensional matrices is gained, by applying mathematical analysis in a theory
that is not purely algebraic. In all these cases the technical difficulties
are much greater.

## [edit] See also

  * List of linear algebra topics
  * Numerical linear algebra

## [edit] Note

  1. ^ Strang, G. 1980. Linear algebra and its Aplications. Second edition. New York: Academic Press. ISBN 012673660X.
  2. ^ E.T. Copson, Preface to Partial Differential Equations, 1973
  3. ^ The existence of a basis is straightforward for finitely generated vector spaces, but in full generality it is logically equivalent to the axiom of choice.

## [edit] References

See also: List of linear algebra references

### [edit] Textbooks

  * Lay, David C. (August 22, 2005), Linear Algebra and Its Applications (3rd ed.), Addison Wesley, ISBN 978-0321287137
  * Meyer, Carl D. (February 15, 2001), Matrix Analysis and Applied Linear Algebra, Society for Industrial and Applied Mathematics (SIAM), ISBN 978-0898714548 . Available online at http://www.matrixanalysis.com/DownloadChapters.html
  * Anton, Howard (2005), Elementary Linear Algebra (Applications Version) (9th ed.), Wiley International
  * Leon, Steven J. (2006), Linear Algebra With Applications (7th ed.), Pearson Prentice Hall

### [edit] Free Online books

  * Beezer, Rob, A First Course in Linear Algebra
  * Connell, Edwin H., Elements of Abstract and Linear Algebra
  * Hefferon, Jim, Linear Algebra excellent textbook with complete solutions manual

### [edit] History

  * Fearnley-Sander, Desmond, "Hermann Grassmann and the Creation of Linear Algebra" (via JSTOR), American Mathematical Monthly 86 (1979), pp. 809â817.
  * Grassmann, Hermann, Die lineale Ausdehnungslehre ein neuer Zweig der Mathematik: dargestellt und durch Anwendungen auf die Ã¼brigen Zweige der Mathematik, wie auch auf die Statik, Mechanik, die Lehre vom Magnetismus und die Krystallonomie erlÃ¤utert, O. Wigand, Leipzig, 1844.

## [edit] External links

Sister project Wikibooks has more on the topic of

Linear algebra  
  * International Linear Algebra Society
  * MIT Professor Gilbert Strang's Linear Algebra Course Homepage : MIT Course Website
  * MIT Linear Algebra Lectures: free videos from MIT OpenCourseWare
  * Streaming MIT Linear Algebra Lectures at Google Video
  * Linear Algebra Toolkit.
  * Linear Algebra on MathWorld.
  * Linear Algebra overview and notation summary on PlanetMath.
  * Matrix and Linear Algebra Terms on Earliest Known Uses of Some of the Words of Mathematics
  * Earliest Uses of Symbols for Matrices and Vectors on Earliest Uses of Various Mathematical Symbols
  * Linear Algebra by Elmer G. Wiens. Interactive web pages for vectors, matrices, linear equations, etc.
  * Linear Algebra Solved Problems: Interactive forums for discussion of linear algebra problems, from the lowest up to the hardest level (Putnam).
  * Linear Algebra for Informatics. JosÃ© Figueroa-O'Farrill, University of Edinburgh
  * Online Notes / Linear Algebra Paul Dawkins, Lamar University
  * Elementary Linear Algebra textbook with solutions
  * Linear Algebra Wiki
  * Linear algebra (math 21b) homework and exercises

  

v â¢ d â¢ e

Topics related to linear algebra  
Scalar Â· Vector Â· Vector space Â· Vector projection Â· Linear span Â· Linear
map Â· Linear projection Â· Linear independence Â· Linear combination Â· Basis
Â· Column space Â· Row space Â· Dual space Â· Orthogonality Â· Rank Â· Minor
Â· Kernel (matrix) Â· Eigenvalue, eigenvector and eigenspace Â· Least squares
regressions Â· Outer product Â· Inner product space Â· Dot product Â·
Transpose Â· GramâSchmidt process Â· Matrix decomposition  
v â¢ d â¢ e

Major fields of mathematics  
Arithmetic Â· Logic Â· Set theory Â· Category theory Â· Algebra (elementary
â linear â abstract) Â· Number theory Â· Analysis (calculus) Â· Geometry
Â· Trigonometry Â· Topology Â· Dynamical systems Â· Combinatorics Â· Game
theory Â· Information theory Â· Optimization Â· Computation Â· Probability Â·
Statistics Â· Mathematical physics  
Retrieved from "http://en.wikipedia.org/wiki/Linear_algebra"

Categories: Linear algebra

##### Views

  * Article
  * Discussion
  * Edit this page
  * History

##### Personal tools

  * Log in / create account

##### Navigation

  * Main page
  * Contents
  * Featured content
  * Current events
  * Random article

##### Search



##### Interaction

  * About Wikipedia
  * Community portal
  * Recent changes
  * Contact Wikipedia
  * Donate to Wikipedia
  * Help

##### Toolbox

  * What links here
  * Related changes
  * Upload file
  * Special pages
  * Printable version
  * Permanent link
  * Cite this page

##### Languages

  * Ø§ÙØ¹Ø±Ø¨ÙØ©
  * à¦¬à¦¾à¦à¦²à¦¾
  * Bosanski
  * CatalÃ 
  * Äesky
  * Dansk
  * Deutsch
  * ÎÎ»Î»Î·Î½Î¹ÎºÎ¬
  * EspaÃ±ol
  * Esperanto
  * ÙØ§Ø±Ø³Û
  * FranÃ§ais
  * Galego
  * íêµ­ì´
  * Hrvatski
  * Bahasa Indonesia
  * Ãslenska
  * Italiano
  * ×¢××¨××ª
  * á¥áá áá£áá
  * LietuviÅ³
  * Magyar
  * ÐÐ°ÐºÐµÐ´Ð¾Ð½ÑÐºÐ¸
  * Nederlands
  * æ¥æ¬èª
  * âªNorsk (bokmÃ¥l)â¬
  * PiemontÃ¨is
  * Polski
  * PortuguÃªs
  * RomÃ¢nÄ
  * Ð ÑÑÑÐºÐ¸Ð¹
  * Shqip
  * Simple English
  * SlovenÅ¡Äina
  * Ð¡ÑÐ¿ÑÐºÐ¸ / Srpski
  * Srpskohrvatski / Ð¡ÑÐ¿ÑÐºÐ¾Ñ ÑÐ²Ð°ÑÑÐºÐ¸
  * Suomi
  * Svenska
  * à®¤à®®à®¿à®´à¯
  * à¹à¸à¸¢
  * Tiáº¿ng Viá»t
  * Ð¢Ð¾Ò·Ð¸ÐºÓ£
  * TÃ¼rkÃ§e
  * Ð£ÐºÑÐ°ÑÐ½ÑÑÐºÐ°
  * Ø§Ø±Ø¯Ù
  * ××Ö´×××©
  * YorÃ¹bÃ¡
  * ä¸­æ

Powered by MediaWiki

Wikimedia Foundation

  * This page was last modified on 3 April 2009, at 19:23.
  * All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)   
Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S.
registered 501(c)(3) tax-deductible nonprofit charity.  

  * Privacy policy
  * About Wikipedia
  * Disclaimers



